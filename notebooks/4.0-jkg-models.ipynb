{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rework this into three parts:\n",
    "\n",
    "1. Setup\n",
    "2. Logistic Regression\n",
    "3. [GridSearchCV](https://campus.datacamp.com/courses/supervised-learning-with-scikit-learn/fine-tuning-your-model?ex=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "1. Import packages\n",
    "2. Import datasets (from pickle files)\n",
    "3. Prepare dataframes/arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle file\n",
    "df_appointments = pd.read_pickle('../data/interim/appointments_df.pickle')\n",
    "df_clean = pd.read_pickle('../data/interim/clean_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index for dataframe\n",
    "df_clean.set_index('Appointment_ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns from df_clean back into df_appointments\n",
    "df_model = df_appointments.join(df_clean, rsuffix='_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate columns from model dataframe\n",
    "drop_columns = ['Patient_ID_clean',\n",
    "                'Gender_clean',\n",
    "                'Scheduled_Date_clean',\n",
    "                'Appointment_Date_clean',\n",
    "                'SMS_sent_clean',\n",
    "                'No_show_clean',\n",
    "                'Neighborhood']\n",
    "df_model.drop(columns=drop_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column: days_diff to show number of days between scheduled date and appointment date\n",
    "df_model['days_diff'] = df_model.date_diff.dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy vars for days of week\n",
    "df_model = df_model.join(pd.get_dummies(df_model.Appointment_Date.dt.dayofweek))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up column names\n",
    "df_model.columns = ['Patient_ID',\n",
    "                    'Gender',\n",
    "                    'Scheduled_Date',\n",
    "                    'Appointment_Date',\n",
    "                    'SMS_sent',\n",
    "                    'No_show',\n",
    "                    'date_diff',\n",
    "                    'Age',\n",
    "                    'Welfare',\n",
    "                    'Hypertension',\n",
    "                    'Diabetes',\n",
    "                    'Alcoholism',\n",
    "                    'Disability',\n",
    "                    'days_diff',\n",
    "                    'Mon',\n",
    "                    'Tue',\n",
    "                    'Wed',\n",
    "                    'Thu',\n",
    "                    'Fri',\n",
    "                    'Sat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraneous columns not needed for modeling\n",
    "unneeded_columns = ['Patient_ID',\n",
    "                    'Scheduled_Date',\n",
    "                    'Appointment_Date',\n",
    "                    'No_show',\n",
    "                    'date_diff',\n",
    "                    'Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to produce arrays for the features and the response variable\n",
    "y = df_model['No_show'].values\n",
    "X = df_model.drop(columns=unneeded_columns).values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35050   319]\n",
      " [ 8688   154]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.80      0.99      0.89     35369\n",
      "        Yes       0.33      0.02      0.03      8842\n",
      "\n",
      "avg / total       0.71      0.80      0.72     44211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\n",
    "\n",
    "# Create the classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Compute and print the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=123456)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "predicted = rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "\n",
    "print(rf.oob_score)\n",
    "print(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, predicted))\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest/Grid Search\n",
    "\n",
    "Source: https://www.fabienplisson.com/random-forest-and-grid-search/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "seed = 123\n",
    " \n",
    "# RFC with fixed hyperparameters max_depth, max_features and min_samples_leaf\n",
    "rfc = RandomForestClassifier(n_jobs=-1, oob_score = True, max_depth=10, max_features='sqrt', min_samples_leaf = 1) \n",
    "\n",
    "# Range of `n_estimators` values to explore.\n",
    "n_estim = filter(lambda x: x % 2 == 0, list(range(10,100)))\n",
    "\n",
    "cv_scores = []\n",
    "\n",
    "for i in n_estim:\n",
    "    rfc.set_params(n_estimators=i)\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    scores = model_selection.cross_val_score(rfc, x_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean()*100)\n",
    "    \n",
    "optimal_n_estim = n_estim[cv_scores.index(max(cv_scores))]\n",
    "print(\"The optimal number of estimators is %d with %0.1f%%\" % (optimal_n_estim, cv_scores[optimal_n_estim]))\n",
    "\n",
    "plt.plot(n_estim, cv_scores)\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('Train Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1) \n",
    "\n",
    "# Use a grid over parameters of interest\n",
    "param_grid = { \n",
    "           \"n_estimators\" : [9, 25, 63],\n",
    "           \"max_depth\" : [1, 10, 30],\n",
    "           \"min_samples_leaf\" : [1, 5, 10]}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 2)\n",
    "CV_rfc.fit(X_train, y_train)\n",
    "print(CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_predicted = CV_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, cv_predicted))\n",
    "print(classification_report(y_test, cv_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3\n",
    "\n",
    "seed = 123\n",
    "\n",
    "# Optimized RF classifier\n",
    "rfc = RandomForestClassifier(n_estimators=36, max_depth=5, max_features='sqrt', min_samples_leaf = 4)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\n",
    "# fit the model with training set\n",
    "scores = model_selection.cross_val_score(rfc, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "cv_scores.append(scores.mean()*100)\n",
    "print(\"Train accuracy %0.2f (+/- %0.2f)\" % (scores.mean()*100, scores.std()*100))\n",
    "\n",
    "# predict on testing set\n",
    "preds = model_selection.cross_val_predict(rfc, X_test, y_test, cv=kfold)\n",
    "cv_preds.append(metrics.accuracy_score(y_test, preds)*100)\n",
    "print(\"Test accuracy %0.2f\" % (100*metrics.accuracy_score(y_test, preds)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle file\n",
    "df_appointments = pd.read_pickle('../data/interim/appointments_df.pickle')\n",
    "df_clean = pd.read_pickle('../data/interim/clean_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index for dataframe\n",
    "df_clean.set_index('Appointment_ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns from df_clean back into df_appointments\n",
    "df_model = df_appointments.join(df_clean, rsuffix='_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate columns from model dataframe\n",
    "drop_columns = ['Patient_ID_clean',\n",
    "                'Gender_clean',\n",
    "                'Scheduled_Date_clean',\n",
    "                'Appointment_Date_clean',\n",
    "                'SMS_sent_clean',\n",
    "                'No_show_clean',\n",
    "                'Neighborhood']\n",
    "df_model.drop(columns=drop_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column: days_diff to show number of days between scheduled date and appointment date\n",
    "df_model['days_diff'] = df_model.date_diff.dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy vars for days of week\n",
    "df_model = df_model.join(pd.get_dummies(df_model.Appointment_Date.dt.dayofweek))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up column names\n",
    "df_model.columns = ['Patient_ID',\n",
    "                    'Gender',\n",
    "                    'Scheduled_Date',\n",
    "                    'Appointment_Date',\n",
    "                    'SMS_sent',\n",
    "                    'No_show',\n",
    "                    'date_diff',\n",
    "                    'Age',\n",
    "                    'Welfare',\n",
    "                    'Hypertension',\n",
    "                    'Diabetes',\n",
    "                    'Alcoholism',\n",
    "                    'Disability',\n",
    "                    'days_diff',\n",
    "                    'Mon',\n",
    "                    'Tue',\n",
    "                    'Wed',\n",
    "                    'Thu',\n",
    "                    'Fri',\n",
    "                    'Sat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraneous columns not needed for modeling\n",
    "unneeded_columns = ['Patient_ID',\n",
    "                    'Scheduled_Date',\n",
    "                    'Appointment_Date',\n",
    "                    'No_show',\n",
    "                    'date_diff',\n",
    "                    'Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to produce arrays for the features and the response variable\n",
    "y = df_model['No_show'].values\n",
    "X = df_model.drop(columns=unneeded_columns).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename 'Yes'/'No' to 'No-show'/'Show' for clarity\n",
    "rename = y.copy()\n",
    "for key, value in {'Yes': 'No-show', 'No': 'Show'}.items(): rename[y == key] = value\n",
    "y = rename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix\n",
      "[[  154  8688]\n",
      " [  319 35050]]\n",
      "True Negative (True Show):\t 35050\n",
      "False Positive (False No-show):\t 319\n",
      "False Negative (False Show):\t 8688\n",
      "True Positive (True No-show):\t 154\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    No-show       0.33      0.02      0.03      8842\n",
      "       Show       0.80      0.99      0.89     35369\n",
      "\n",
      "avg / total       0.71      0.80      0.72     44211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\n",
    "\n",
    "# Create the classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Compute and print the confusion matrix and classification report\n",
    "logreg_cm = confusion_matrix(y_test, y_pred)\n",
    "true_pos, false_neg, false_pos, true_neg = logreg_cm.ravel()\n",
    "print('\\nConfusion Matrix')\n",
    "print(logreg_cm)\n",
    "print('True Negative (True Show):\\t', true_neg)\n",
    "print('False Positive (False No-show):\\t', false_pos)\n",
    "print('False Negative (False Show):\\t', false_neg)\n",
    "print('True Positive (True No-show):\\t', true_pos)\n",
    "\n",
    "logreg_cr = classification_report(y_test, y_pred)\n",
    "print('\\nClassification Report')\n",
    "print(logreg_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate GridSearchCV object\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([1.00000e-05, 8.48343e-05, 7.19686e-04, 6.10540e-03, 5.17947e-02,\n",
       "       4.39397e-01, 3.72759e+00, 3.16228e+01, 2.68270e+02, 2.27585e+03,\n",
       "       1.93070e+04, 1.63789e+05, 1.38950e+06, 1.17877e+07, 1.00000e+08])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit data\n",
    "logreg_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'C': 0.0007196856730011522}\n",
      "Best score is 0.7945141443995416\n"
     ]
    }
   ],
   "source": [
    "# print tuned parameter and score\n",
    "print('Tuned Logistic Regression Parameters: {}'.format(logreg_cv.best_params_))\n",
    "print('Best score is {}'.format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cv = logreg_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix (GridSearchCV)\n",
      "[[  162  8680]\n",
      " [  253 35116]]\n",
      "True Negative (True Show):\t 35116\n",
      "False Positive (False No-show):\t 253\n",
      "False Negative (False Show):\t 8680\n",
      "True Positive (True No-show):\t 162\n",
      "\n",
      "Classification Report (GridSearchCV)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    No-show       0.39      0.02      0.04      8842\n",
      "       Show       0.80      0.99      0.89     35369\n",
      "\n",
      "avg / total       0.72      0.80      0.72     44211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute and print the confusion matrix and classification report\n",
    "logreg_cv_cm = confusion_matrix(y_test, y_pred_cv)\n",
    "true_pos_cv, false_neg_cv, false_pos_cv, true_neg_cv = logreg_cv_cm.ravel()\n",
    "print('\\nConfusion Matrix (GridSearchCV)')\n",
    "print(logreg_cv_cm)\n",
    "print('True Negative (True Show):\\t', true_neg_cv)\n",
    "print('False Positive (False No-show):\\t', false_pos_cv)\n",
    "print('False Negative (False Show):\\t', false_neg_cv)\n",
    "print('True Positive (True No-show):\\t', true_pos_cv)\n",
    "\n",
    "logreg_cv_cr = classification_report(y_test, y_pred_cv)\n",
    "print('\\nClassification Report (GridSearchCV)')\n",
    "print(logreg_cv_cr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
